{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of how to execute the model by modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import kornia as K\n",
    "from kornia import augmentation as A\n",
    "from kornia.augmentation import AugmentationSequential\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# if cuda is avaliable, use it\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "images_path = '../dataset/train/images'\n",
    "annotations_path = '../dataset/train/annotations'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to translate format from json to kornia and vice versa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_kornia_format(data):\n",
    "    # Extract the bounding boxes and keypoints from the dictionary\n",
    "    bboxes = data['bboxes']\n",
    "    keypoints = data['keypoints']\n",
    "\n",
    "    # Convert the bounding boxes to the Kornia format\n",
    "    bbox_list = []\n",
    "    for bbox in bboxes:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        bbox_list.append([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])\n",
    "    bbox_tensor = torch.tensor(bbox_list).unsqueeze(0)\n",
    "\n",
    "    # Convert the keypoints to the Kornia format\n",
    "    keypoint_list = []\n",
    "    for kpts in keypoints:\n",
    "        for kpt in kpts:\n",
    "            x, y, _ = kpt\n",
    "            keypoint_list.append([x, y])\n",
    "    keypoint_tensor = torch.tensor(keypoint_list).unsqueeze(0)\n",
    "\n",
    "    return bbox_tensor, keypoint_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kornia_to_torch_format(bbox_tensor, keypoint_tensor, labels=None):\n",
    "    \"\"\"\n",
    "    Convert bbox_tensor and keypoint_tensor in Kornia format to torch's expected format.\n",
    "    \n",
    "    Parameters:\n",
    "    - bbox_tensor (torch.Tensor): Bounding box tensor in Kornia format\n",
    "    - keypoint_tensor (torch.Tensor): Keypoint tensor in Kornia format\n",
    "    - labels (list[int]): List of class labels for each bounding box. If None, default to label=1 for all boxes.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary with 'boxes', 'labels', and 'keypoints' in the format expected by torch.\n",
    "    \"\"\"\n",
    "    # Convert bbox_tensor from Kornia's format to torch's [x1, y1, x2, y2] format\n",
    "    boxes = torch.stack([bbox_tensor[0,:,0,0], bbox_tensor[0,:,0,1], bbox_tensor[0,:,2,0], bbox_tensor[0,:,2,1]], dim=1)\n",
    "    \n",
    "    # If labels aren't provided, assume a default label of 1 for all bounding boxes\n",
    "    if labels is None:\n",
    "        labels = torch.ones((bbox_tensor.shape[1],), dtype=torch.int64)\n",
    "    else:\n",
    "        labels = torch.tensor(labels, dtype=torch.int64).to(device)\n",
    "    \n",
    "    # Convert keypoint_tensor to the desired [x, y, visibility] format\n",
    "    keypoints = torch.zeros((bbox_tensor.shape[1], keypoint_tensor.shape[1]//bbox_tensor.shape[1], 3))\n",
    "    for i in range(bbox_tensor.shape[1]):\n",
    "        keypoints[i, :, :2] = keypoint_tensor[0, i*2:(i+1)*2, :]\n",
    "        keypoints[i, :, 2] = 1  # setting visibility to 1\n",
    "    \n",
    "    return {\"boxes\": boxes.float().to(device), \"labels\": labels.to(device), \"keypoints\": keypoints.to(device)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's go to load image and annotations from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON:\n",
      "{'bboxes': [[692, 346, 904, 504], [1076, 364, 1236, 572]], 'keypoints': [[[881, 479, 1], [709, 372, 1]], [[1212, 387, 1], [1102, 552, 1]]]}\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Kornia\n",
      "tensor([[[[ 692,  346],\n",
      "          [ 904,  346],\n",
      "          [ 904,  504],\n",
      "          [ 692,  504]],\n",
      "\n",
      "         [[1076,  364],\n",
      "          [1236,  364],\n",
      "          [1236,  572],\n",
      "          [1076,  572]]]])\n",
      "tensor([[[ 881,  479],\n",
      "         [ 709,  372],\n",
      "         [1212,  387],\n",
      "         [1102,  552]]])\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training:\n",
      "{'boxes': tensor([[ 692.,  346.,  904.,  504.],\n",
      "        [1076.,  364., 1236.,  572.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'keypoints': tensor([[[8.8100e+02, 4.7900e+02, 1.0000e+00],\n",
      "         [7.0900e+02, 3.7200e+02, 1.0000e+00]],\n",
      "\n",
      "        [[1.2120e+03, 3.8700e+02, 1.0000e+00],\n",
      "         [1.1020e+03, 5.5200e+02, 1.0000e+00]]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "# get all images in the folder using os\n",
    "image_filenames = [filename for filename in os.listdir(images_path) if filename.endswith('.jpg')]\n",
    "\n",
    "for image_filename in image_filenames:\n",
    "    \n",
    "    image = cv2.imread(os.path.join(images_path, image_filename))\n",
    "\n",
    "    # convert to tensor\n",
    "    image_tensor: torch.Tensor = K.image_to_tensor(image).to(device)\n",
    "\n",
    "    # bgr to rgb\n",
    "    image_tensor = K.color.bgr_to_rgb(image_tensor)\n",
    "\n",
    "    image_tensor = K.enhance.normalize(image_tensor, torch.tensor(0.), torch.tensor(255.)).to(device)\n",
    "\n",
    "    annotation_filename = os.path.join(annotations_path, image_filename[:-4] + '.json')\n",
    "    with open(annotation_filename, 'r') as f:\n",
    "        annotation = json.load(f)\n",
    "    print('JSON:')    \n",
    "    print(annotation)\n",
    "    print('-'*200)\n",
    "    print('Kornia')\n",
    "    bbox_tensor, keypoint_tensor = convert_to_kornia_format(annotation)\n",
    "    print(bbox_tensor)\n",
    "    print(keypoint_tensor)\n",
    "    print('-'*200)\n",
    "    print('Training:') \n",
    "    targets = kornia_to_torch_format(bbox_tensor, keypoint_tensor)\n",
    "    print(targets)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "(<torchvision.models.detection.image_list.ImageList object at 0x7f14fc0db850>, [{'boxes': tensor([[480.4354, 239.9574, 627.6208, 349.5333],\n",
      "        [747.0355, 252.4407, 858.1188, 396.6926]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'keypoints': tensor([[[611.6526, 332.1954,   1.0000],\n",
      "         [492.2380, 257.9889,   1.0000]],\n",
      "\n",
      "        [[841.4563, 268.3917,   1.0000],\n",
      "         [765.0865, 382.8222,   1.0000]]], device='cuda:0')}])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import KeypointRCNN_ResNet50_FPN_Weights\n",
    "# if cuda is avaliable, use it\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# empty cuda cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = torchvision.models.detection.keypointrcnn_resnet50_fpn(weights=KeypointRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "model.to(device).eval()\n",
    "# print(model)\n",
    "\n",
    "transform_result = model.transform(image_tensor.unsqueeze(0), [targets])\n",
    "print(transform_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BackboneWithFPN(\n",
      "  (body): IntermediateLayerGetter(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fpn): FeaturePyramidNetwork(\n",
      "    (inner_blocks): ModuleList(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): Conv2dNormActivation(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (3): Conv2dNormActivation(\n",
      "        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (layer_blocks): ModuleList(\n",
      "      (0-3): 4 x Conv2dNormActivation(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (extra_blocks): LastLevelMaxPool()\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(model.backbone)\n",
    "features = model.backbone(transform_result[0].tensors)\n",
    "print('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "proposals, proposal_losses = model.rpn(transform_result[0], features, [targets])\n",
    "print('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "detections, detector_losses = model.roi_heads(features, proposals, transform_result[0].image_sizes, [targets])\n",
    "# detections = model.transform.postprocess(detections,  transform_result[0].image_sizes, image_tensor.shape[-2:])\n",
    "model_detector_losses = model(image_tensor.unsqueeze(0), [targets])\n",
    "print(detector_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
